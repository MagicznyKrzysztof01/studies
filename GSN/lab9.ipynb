{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRya3-1t7gO7"
      },
      "source": [
        "# Wstęp\n",
        "\n",
        "Metody uczenia maszynowego możemy podzielić na dwie główne kategorie (pomijając uczenie ze wzmocnieniem): nadzorowane i nienadzorowane. Uczenie **nadzorowane** (ang. *supervised*) to jest uczenie z dostępnymi etykietami dla danych wejściowych. Na parach danych uczących $dataset= \\{(x_0,y_0), (x_1,y_1), \\ldots, (x_n,y_n)\\}$ model ma za zadanie nauczyć się funkcji $f: X \\rightarrow Y$. Z kolei modele uczone w sposób **nienadzorowany** (ang. *unsupervised*) wykorzystują podczas trenowania dane nieetykietowane tzn. nie znamy $y$ z pary $(x, y)$.\n",
        "\n",
        "Dość częstą sytuacją, z jaką mamy do czynienia, jest posiadanie małego podziobioru danych etykietowanych i dużego nieetykietowanych. Często annotacja danych wymaga ingerencji człowieka - ktoś musi określić co jest na obrazku, ktoś musi powiedzieć czy dane słowo jest rzeczownkiem czy czasownikiem itd.\n",
        "\n",
        "Jeżeli mamy dane etykietowane do zadania uczenia nadzorowanego (np. klasyfikacja obrazka), ale także dużą ilość danych nieetykietowanych, to możemy wtedy zastosować techniki **uczenia częściowo nadzorowanego** (ang. *semi-supervised learning*). Te techniki najczęściej uczą się funkcji $f: X \\rightarrow Y$, ale jednocześnie są w stanie wykorzystać informacje z danych nieetykietowanych do poprawienia działania modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjjlvGdZNg00"
      },
      "source": [
        "## Cel ćwiczenia\n",
        "\n",
        "Celem ćwiczenia jest nauczenie modelu z wykorzystaniem danych etykietowanych i nieetykietowanych ze zbioru STL10 z użyciem metody [Bootstrap your own latent](https://arxiv.org/abs/2006.07733).\n",
        "\n",
        "Metoda ta jest relatywnie \"lekka\" obliczeniowo, a także dość prosta do zrozumienia i zaimplementowania, dlatego też na niej się skupimy na tych laboratoriach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI8ZMEH2NkgA"
      },
      "source": [
        "# Zbiór STL10\n",
        "\n",
        "Zbiór STL10 to zbiór stworzony i udostępniony przez Stanford [[strona]](https://ai.stanford.edu/~acoates/stl10/) [[papier]](https://cs.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf) a inspirowany przez CIFAR-10. Obrazy zostały pozyskane z [ImageNet](https://image-net.org/). Szczegóły można doczytać na ich stronie. To co jest ważne to to, że autorzy zbioru dostarczają predefiniowany plan eksperymentalny, żeby móc porównywać łatwo wyniki eksperymentów. Nie będziemy go tutaj stosować z uwagi na jego czasochłonność (10 foldów), ale warto pamiętać o tym, że często są z góry ustalone sposoby walidacji zaprojetowanych przez nas algorytmów na określonych zbiorach referencyjnych.\n",
        "\n",
        "Korzystając z `torchvision.datasets` ***załaduj*** 3 podziały zbioru danych STL10: `train`, `test`, `unlabeled` oraz utwórz z nich instancje klasy `DataLoader`. Korzystając z Google Colab rozważ użycie Google Drive do przechowyania zbioru w calu zaoszczędzenia czasu na wielokrotne pobieranie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hC8VhuEoR90S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import STL10\n",
        "# Definiuję ścieżkę do mojego katalogu na Google Drive\n",
        "data_dir = \"/content/drive/MyDrive/stl10_data\"\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "# Załaduj zbiory train, test i unlabeled\n",
        "train_dataset = datasets.STL10(root=data_dir, split='train', transform=transform, download=False)\n",
        "test_dataset = datasets.STL10(root=data_dir, split='test', transform=transform, download=False)\n",
        "# unlabeled_dataset = datasets.STL10(root=data_dir, split='unlabeled', transform=transform, download=False)\n",
        "\n",
        "# Utwórz DataLoader dla każdego podziału\n",
        "train_dl = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_dl = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "# unlabeled_dl = DataLoader(unlabeled_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4qyXdlLZHzn"
      },
      "source": [
        "# Uczenie nadzorowane\n",
        "\n",
        "Żeby porównać czy metoda BYOL przynosi nam jakieś korzyści musimy wyznaczyć wartość bazową metryk(i) jakości, których będziemu używać (np. dokładność).\n",
        "\n",
        "***Zaimplementuj*** wybraną metodę uczenia nadzorowanego na danych `train` z STL10. Możesz wykorzystać predefiniowane architektury w `torchvision.models` oraz kody źródłowe z poprzednich list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l2vcmEhEaA2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\krzys\\anaconda3\\envs\\GSN\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\krzys\\anaconda3\\envs\\GSN\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from typing import Tuple\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = 'cpu'\n",
        "resnet18 = models.resnet18(pretrained=False)\n",
        "# vgg19.classifier[6] = nn.Linear(4096, 10, bias=True)  # STL10 ma 10 klas\n",
        "# model = vgg19.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_correct(\n",
        "    y_pred: torch.Tensor, y_true: torch.Tensor\n",
        ") -> torch.Tensor:\n",
        "    preds = torch.argmax(y_pred, dim=1)\n",
        "    return (preds == y_true).float().sum()\n",
        "\n",
        "def validate(\n",
        "    model: nn.Module, \n",
        "    loss_fn: torch.nn.CrossEntropyLoss, \n",
        "    dataloader: DataLoader\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    all = 0\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        y_pred = model(X_batch.to(device))\n",
        "        all += len(y_pred)\n",
        "        loss += loss_fn(y_pred, y_batch.to(device)).sum()\n",
        "        correct += count_correct(y_pred, y_batch.to(device))\n",
        "    return loss / all, correct / all\n",
        "\n",
        "def fit(\n",
        "    model: nn.Module, optimiser: optim.Optimizer, \n",
        "    loss_fn: torch.nn.CrossEntropyLoss, train_dl: DataLoader, \n",
        "    val_dl: DataLoader, epochs: int, \n",
        "    print_metrics: str = True\n",
        "):\n",
        "  for epoch in range(epochs):\n",
        "      for X_batch, y_batch in tqdm(train_dl):\n",
        "          y_pred = model(X_batch.to(device))\n",
        "          loss = loss_fn(y_pred, y_batch.to(device))\n",
        "\n",
        "          loss.backward()\n",
        "          optimiser.step()\n",
        "          optimiser.zero_grad()\n",
        "\n",
        "      if print_metrics: \n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "              train_loss, train_acc = validate(\n",
        "                  model=model, loss_fn=loss_fn, dataloader=train_dl\n",
        "              ) \n",
        "              val_loss, val_acc = validate(\n",
        "                  model=model, loss_fn=loss_fn, dataloader=val_dl\n",
        "              )\n",
        "              print(\n",
        "                  f\"Epoch {epoch}: \"\n",
        "                  f\"train loss = {train_loss:.3f} (acc: {train_acc:.3f}), \"\n",
        "                  f\"validation loss = {val_loss:.3f} (acc: {val_acc:.3f})\"\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNetSTL10(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetSTL10, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        num_ftrs = resnet.fc.in_features\n",
        "        resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        self.resnet = resnet\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# Liczba klas w zbiorze danych STL10\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:05<00:00,  6.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.016 (acc: 0.380), validation loss = 0.017 (acc: 0.345)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 10.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.013 (acc: 0.365), validation loss = 0.013 (acc: 0.354)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 10.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.014 (acc: 0.382), validation loss = 0.014 (acc: 0.358)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 10.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.011 (acc: 0.452), validation loss = 0.011 (acc: 0.421)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 11.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.011 (acc: 0.504), validation loss = 0.012 (acc: 0.462)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 11.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss = 0.010 (acc: 0.552), validation loss = 0.011 (acc: 0.488)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 11.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: train loss = 0.009 (acc: 0.585), validation loss = 0.010 (acc: 0.523)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 11.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: train loss = 0.009 (acc: 0.573), validation loss = 0.011 (acc: 0.490)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 11.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: train loss = 0.011 (acc: 0.522), validation loss = 0.013 (acc: 0.435)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:03<00:00, 11.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: train loss = 0.009 (acc: 0.606), validation loss = 0.012 (acc: 0.504)\n"
          ]
        }
      ],
      "source": [
        "model_finetuned = ResNetSTL10(10)\n",
        "model_finetuned.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_finetuned = torch.optim.Adam(model_finetuned.parameters(), lr=0.001)\n",
        "fit(model_finetuned, optimizer_finetuned, criterion, train_dl, test_dl, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saaKpwl0FVII"
      },
      "source": [
        "# Bootstrap your own latent\n",
        "\n",
        "Metoda [Bootstrap your own latent](https://arxiv.org/abs/2006.07733) jest opisana w rodziale 3.1 papieru a także w dodatku A. Składa się z dwóch etapów:\n",
        "\n",
        "\n",
        "1.   uczenia samonadzorowanego (ang. *self-supervised*)\n",
        "2.   douczania nadzorowanego (ang. *fine-tuning*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b8L_zYGNs_K"
      },
      "source": [
        "## Uczenie samonadzorowane\n",
        "\n",
        "Architektura do nauczania samonadzorowanego składa się z dwóch sieci: (1) *online* i (2) *target*. W uproszczeniu cała architektura działa tak:\n",
        "\n",
        "\n",
        "1.   Dla obrazka $x$ wygeneruj dwie różne augmentacje $v$ i $v'$ za pomocą funkcji $t$ i $t'$.\n",
        "2.   Widok $v$ przekazujemy do sieci *online*, a $v'$ do *target*.\n",
        "3.   Następnie widoki przekształacamy za pomocą sieci do uczenia reprezentacji (np. resnet18 lub resnet50) do reprezentacji $y_\\theta$ i $y'_\\xi$.\n",
        "4.   Potem dokonujemy projekcji tych reprezentacji w celu zmniejszenia wymiarowości (np. za pomocą sieci MLP).\n",
        "5.   Na sieci online dokonujmey dodatkowo predykcji pseudo-etykiety (ang. *pseudolabel*)\n",
        "6.   Wyliczamy fukncję kosztu: MSE z wyjścia predyktora sieci *online* oraz wyjścia projekcji sieci *target* \"przepuszczonej\" przez predyktor sieci *online* **bez propagacji wstecznej** (*vide Algorithm 1* z papieru).\n",
        "7.   Dokonujemy wstecznej propagacji **tylko** po sieci *online*.\n",
        "8.   Aktualizujemy wagi sieci *target* sumując w ważony sposób wagi obu sieci $\\xi = \\tau\\xi + (1 - \\tau)\\theta$ ($\\tau$ jest hiperprametrem) - jest to ruchoma średnia wykładnicza (ang. *moving exponential average*).\n",
        "\n",
        "Po zakończeniu procesu uczenia samonadzorowanego zostawiamy do douczania sieć kodera *online* $f_\\theta$. Cała sieć *target* oraz warstwy do projekcji i predykcji w sieci *online* są \"do wyrzucenia\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFIRw--bTYe5"
      },
      "source": [
        "### Augmentacja\n",
        "\n",
        "Dodatek B publikacji opisuje augmentacje zastosowane w metodzie BYOL. Zwróć uwagę na tabelę 6 w publikacji. `torchvision.transforms.RandomApply` może być pomocne.\n",
        "\n",
        "***Zaimeplementuj*** augmentację $\\tau$ i $\\tau'$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "csbR-Bvy8IbZ"
      },
      "outputs": [],
      "source": [
        "augmentation_t = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.8),\n",
        "    transforms.RandomApply([transforms.RandomGrayscale(p=1.0)], p=0.2),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0))], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "augmentation_t_prime = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.8),\n",
        "    transforms.RandomApply([transforms.RandomGrayscale(p=1.0)], p=0.2),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0))], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "stl10_ds_unlabeled_transformed = STL10(\n",
        "    root=data_dir,\n",
        "    split='unlabeled',\n",
        "    transform=augmentation_t,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "\n",
        "stl10_ds_unlabeled_transformed_prime = STL10(\n",
        "    root=data_dir,\n",
        "    split='unlabeled',\n",
        "    transform=augmentation_t_prime,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "transform_t_loader = DataLoader(\n",
        "    stl10_ds_unlabeled_transformed,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        ")\n",
        "\n",
        "transform_t_prime_loader = DataLoader(\n",
        "    stl10_ds_unlabeled_transformed_prime,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKMQGx8FtoF"
      },
      "source": [
        "### Implementacja uczenia samonadzorowanego\n",
        "\n",
        "***Zaprogramuj*** proces uczenia samonadzorowanego na danych nieetykietowanych ze zbioru STL10.\n",
        "\n",
        "Wskazówki do realizacji polecenia:\n",
        "\n",
        "1. Proces uczenia może trwać bardzo długo dlatego zaleca się zastsowanie wczesnego zatrzymania lub uczenia przez tylko jedną epokę. Mimo wszystko powinno się dać osiągnąć poprawę w uczeniu nadzorowanym wykorzystując tylko zasoby z Google Colab.\n",
        "2. Dobrze jest pominąć walidację na zbiorze treningowym i robić ją tylko na zbiorze walidacyjnym - zbiór treningowy jest ogromny i w związku z tym narzut czasowy na walidację też będzie duży.\n",
        "3. Walidację modelu można przeprowadzić na zbiorze `train` lub całkowicie ją pominąć, jeżeli uczymy na stałej ilości epok.\n",
        "4. Rozważ zastosowanie tylko jednej augmentacji - augmentacja $\\tau'$ jest bardziej czasochłonna niż $\\tau$.\n",
        "5. Poniżej jest zaprezentowany zalążek kodu - jest on jedynie wskazówką i można na swój sposób zaimplementować tę metodę"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from torch import nn\n",
        "import torch.functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int, projector: bool = False):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "        if projector:\n",
        "            self.net.append(nn.BatchNorm1d(output_size))\n",
        "            self.net.append(nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        return self.net(x)\n",
        "    \n",
        "class BYOL(nn.Module):\n",
        "    def __init__(self, model, input_size=1000, hidden_size= 1024, projection_size=256, tau = 0.99) -> None:\n",
        "        super().__init__()\n",
        "        self.online_encoder = model\n",
        "        self.online_projector = MLP(input_size, hidden_size, projection_size, projector= True)\n",
        "        self.online_predictor = MLP(projection_size, hidden_size, projection_size, projector= False)\n",
        "        self.online_net = nn.Sequential(\n",
        "            self.online_encoder, \n",
        "            self.online_projector, \n",
        "        )\n",
        "\n",
        "        self.target_encoder = self.deepcopy_and_freeze(self.online_encoder)\n",
        "        self.target_projector = self.deepcopy_and_freeze(self.online_projector)\n",
        "        self.target_net = nn.Sequential(self.target_encoder, self.target_projector)\n",
        "\n",
        "        self.tau = tau\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        z1 = self.online_net(x1)\n",
        "        z2 = self.online_net(x2)\n",
        "        p1 = self.online_predictor(z1)\n",
        "        p2 = self.online_predictor(z2)\n",
        "        return z1, z2, p1, p2\n",
        "\n",
        "    def update_target(self):\n",
        "        for online_params, target_params in zip(self.online_net.parameters(), self.target_net.parameters()):\n",
        "            target_params.data = self.tau * target_params.data + (1 - self.tau) * online_params.data\n",
        "\n",
        "    def loss(self, z1, z2, p1, p2):\n",
        "        z2 = z2.detach()\n",
        "        p2 = p2.detach()\n",
        "        return 0.5 * (nn.functional.mse_loss(p1, z2) + nn.functional.mse_loss(p2, z1))\n",
        "    \n",
        "    @staticmethod\n",
        "    def deepcopy_and_freeze(model: nn.Module) -> nn.Module:\n",
        "        model_copy = deepcopy(model)\n",
        "        for param in model_copy.parameters():\n",
        "            param.requires_grad = False\n",
        "        return model_copy    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_byol(model, optimizer, train_dl, train_dl_prime, epochs=10, patience=5):\n",
        "    metrics = {'train_loss': []}\n",
        "    best_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x1, _), (x2, _) in tqdm(zip(train_dl, train_dl_prime), total=784):\n",
        "            x1, x2 = x1.to(device), x2.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            z1, z2, p1, p2 = model(x1, x2)\n",
        "            loss = model.loss(z1, z2, p1, p2)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            model.update_target()\n",
        "\n",
        "            epoch_train_loss += loss.item() * x1.size(0)\n",
        "            total += x1.size(0)\n",
        "\n",
        "        train_loss = epoch_train_loss / total\n",
        "        metrics['train_loss'].append(train_loss)\n",
        "        print(f\"Epoch {epoch}: train loss = {train_loss:.3f}\")\n",
        "\n",
        "        if train_loss < best_loss:\n",
        "            best_loss = train_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                early_stop = True\n",
        "                break\n",
        "\n",
        "        if early_stop:\n",
        "            print(\"Training stopped early\")\n",
        "            break\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.resnet18 = resnet18\n",
        "        in_ftrs = self.resnet18.fc.in_features\n",
        "        self.resnet18.fc = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = torch.randn(512,3,96,96)\n",
        "res = models.resnet18(pretrained=False)\n",
        "t = res(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 782/784 [1:33:15<00:14,  7.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.014\n"
          ]
        }
      ],
      "source": [
        "model = BYOL(models.resnet18(pretrained=False)).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "results = fit_byol(\n",
        "    model,\n",
        "    optimizer,\n",
        "    transform_t_loader,\n",
        "    transform_t_prime_loader,\n",
        "    epochs=1,\n",
        "    patience=7\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qitno0wc8W35"
      },
      "source": [
        "## Douczanie nadzorowane\n",
        "\n",
        "***Zaimplementuj*** proces douczania kodera z poprzedniego polecenia na danych etykietowanych ze zbioru treningowego. Porównaj jakość tego modelu z modelem nauczonym tylko na danych etykietownaych. Postaraj się wyjaśnić różnice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:40<00:00,  1.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.022 (acc: 0.223), validation loss = 0.021 (acc: 0.225)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.014 (acc: 0.300), validation loss = 0.014 (acc: 0.306)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.013 (acc: 0.335), validation loss = 0.013 (acc: 0.336)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.012 (acc: 0.403), validation loss = 0.012 (acc: 0.384)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.012 (acc: 0.431), validation loss = 0.012 (acc: 0.412)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss = 0.012 (acc: 0.451), validation loss = 0.012 (acc: 0.433)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: train loss = 0.010 (acc: 0.482), validation loss = 0.011 (acc: 0.455)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: train loss = 0.011 (acc: 0.472), validation loss = 0.011 (acc: 0.445)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: train loss = 0.011 (acc: 0.490), validation loss = 0.012 (acc: 0.445)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: train loss = 0.010 (acc: 0.533), validation loss = 0.011 (acc: 0.481)\n"
          ]
        }
      ],
      "source": [
        "state_dict = model.online_encoder.state_dict()\n",
        "encoder = nn.Sequential(\n",
        "    deepcopy(model.online_encoder),\n",
        "    nn.Linear(1000,10)\n",
        ").to(device)\n",
        "# encoder.load_state_dict(state_dict)\n",
        "supervised_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "fit(model=encoder, optimiser=supervised_optimizer, loss_fn=criterion, train_dl=train_dl, val_dl=test_dl, epochs=10, print_metrics=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
